{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.17","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11848,"databundleVersionId":862157,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Imports","metadata":{"id":"4sUPwqPca-XF"}},{"cell_type":"code","source":"!pip install -U \"jax[tpu]\" optuna-dashboard plotly nbformat optuna grain clu jdc munch omegaconf aim","metadata":{"id":"jszXvwoFc1Us","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b34b07a8-d0ba-42bd-e8b9-92d43cf9c859","trusted":true,"execution":{"iopub.status.busy":"2025-06-04T20:12:02.480448Z","iopub.execute_input":"2025-06-04T20:12:02.480758Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: jax[tpu] in /usr/local/lib/python3.10/site-packages (0.4.34)\nCollecting jax[tpu]\n  Downloading jax-0.6.1-py3-none-any.whl (2.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting optuna-dashboard\n  Downloading optuna_dashboard-0.18.0-py3-none-any.whl (8.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting plotly\n  Downloading plotly-6.1.2-py3-none-any.whl (16.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: nbformat in /usr/local/lib/python3.10/site-packages (5.10.4)\nCollecting optuna\n  Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting grain\n  Downloading grain-0.2.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (479 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m479.0/479.0 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting clu\n  Downloading clu-0.0.12-py3-none-any.whl (101 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting jdc\n  Downloading jdc-0.0.9-py2.py3-none-any.whl (2.1 kB)\nCollecting munch\n  Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\nCollecting omegaconf\n  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting aim\n  Downloading aim-3.29.1-cp310-cp310-manylinux_2_28_x86_64.whl (7.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting ml_dtypes>=0.5.0\n  Downloading ml_dtypes-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hCollecting jaxlib<=0.6.1,>=0.6.1\n  Downloading jaxlib-0.6.1-cp310-cp310-manylinux2014_x86_64.whl (89.0 MB)\n\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m89.0/89.0 MB\u001b[0m \u001b[31m166.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m00:01\u001b[0m","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# pip install -U \"jax[cuda12]\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom numpy.typing import NDArray\nfrom typing import List, Any, Tuple, Dict\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib.image as mpimg\nfrom pathlib import Path\nimport tensorflow as tf\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nfrom math import ceil\nimport jax, jax.numpy as jnp, optax, jax.random as jr\n\nfrom flax import linen as nn\nfrom flax.training import train_state  # Useful dataclass to keep train state\n\nimport gc\n\nimport optuna\nfrom optuna.visualization import plot_contour, plot_param_importances, plot_optimization_history, plot_slice, plot_parallel_coordinate\n\nimport logging\nimport sys\n\nfrom omegaconf import OmegaConf\n\nimport torch\nfrom functools import partial\nfrom tqdm import tqdm\nfrom torch.utils.tensorboard import SummaryWriter\nfrom datetime import datetime\nfrom jax.sharding import PartitionSpec as P, NamedSharding\nimport random\nimport orbax.checkpoint as ocp\nfrom etils import epath\nimport json\nfrom grain.python import ShardByJaxProcess, Batch\n\nfrom clu import metrics\nfrom flax import struct     \nimport glob\n\nimport time\nimport threading\nfrom optuna_dashboard import wsgi\nimport optuna\nfrom wsgiref.simple_server import make_server\n\nimport jdc\n%matplotlib inline","metadata":{"id":"lV-IPTcOUkdx","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Project Topic: **CNN Cancer Detection Kaggle Mini-Project**","metadata":{"id":"SgtYW2IPMYTN"}},{"cell_type":"markdown","source":"### Exploratory Data Analysis","metadata":{"id":"ZdJg6c4gOafO"}},{"cell_type":"code","source":"WRK_DIR = '/kaggle/input/histopathologic-cancer-detection'\nTRAIN_DIR = f'{WRK_DIR}/train/'\nTEST_DIR = f'{WRK_DIR}/test/'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/histopathologic-cancer-detection/train_labels.csv')\ndf_test = pd.DataFrame({'path': glob.glob(os.path.join(TEST_DIR, '*.tif'))})\n# df_test['id'] = df_test['path'].str.extract(r'([^//]+).tif$')\nLABEL_MAPPER  = {0: '0: No Cancer', 1: '1: Cancer'}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train['image_path'] = TRAIN_DIR + df_train['id']+'.tif'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train.drop('id', inplace=True, axis=1)\ndf_train['label'] = df_train['label'].astype(str)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_test.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df_train.info())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df_test.info())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# number of files in the train folder = size of train dataset\ntrain_files = glob.glob(os.path.join(TRAIN_DIR, '*.tif'))\nprint(len(train_files))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# number of files in the test folder = size of test dataset\ntest_files = glob.glob(os.path.join(TEST_DIR, '*.tif'))\nprint(len(test_files))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig,ax=plt.subplots(1,2,figsize=(10,5))\ndf_train.label.value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%',ax=ax[0],shadow=True, labels=LABEL_MAPPER.values())\nax[0].set_ylabel('')\nsns.countplot(df_train, x='label', ax=ax[1])\nfig.suptitle(\"Class Distribution\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"As seen from the plot above, the dataset is mildly imbalanced$^\\href{https://developers.google.com/machine-learning/crash-course/overfitting/imbalanced-datasets}{1}$ with the majority class being 0 (No cancer - Negative class) and minority class as 1 (presence of cancer - Postive class).","metadata":{"id":"nqP7Bk-1r72l"}},{"cell_type":"code","source":"#https://matplotlib.org/stable/gallery/axes_grid1/demo_axes_grid2.html#sphx-glr-gallery-axes-grid1-demo-axes-grid2-py\ndef add_inner_title(ax, title, loc, **kwargs):\n    from matplotlib.offsetbox import AnchoredText\n    from matplotlib.patheffects import withStroke\n    prop = dict(path_effects=[withStroke(foreground='w', linewidth=2)],\n                size=plt.rcParams['legend.fontsize'])\n    at = AnchoredText(title, loc=loc, prop=prop,\n                      pad=0., borderpad=0.5,\n                      frameon=False, **kwargs)\n    ax.add_artist(at)\n    return at","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def show_images(dirs: List[Tuple[str, int]], preds: List[int] = []) -> None:\n    assert isinstance(dirs, list) and dirs, 'must be a list of valid image paths/files'\n    if len(preds)>0:\n        assert isinstance(preds, list) and len(preds)==len(dirs), 'if provided, preds must be list of predictions and must be of same len with dirs'\n    fig = plt.figure(figsize=(10., 10.))\n    mm = [ (mpimg.imread(img), im_title) for img, im_title in dirs if os.path.exists(img) ]\n    grid = ImageGrid(fig, 111, \n                     nrows_ncols=(ceil(len(dirs)/3), 3),\n                     axes_pad=0.05, label_mode=\"all\"\n                 )\n    for i, (ax, (im, im_title)) in enumerate(zip(grid, mm)):\n        ax.imshow(im)\n        add_inner_title(ax,  f'true: {LABEL_MAPPER[im_title]}', loc='upper left')\n        if preds:\n            add_inner_title(ax, f'\\npredicted: {preds[i]}', loc='upper left')\n        \n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"show_images([(f'{TRAIN_DIR}f38a6374c348f90b587e046aac6079959adf3835.tif', 0), \n             (f'{TRAIN_DIR}f38a6374c348f90b587e046aac6079959adf3835.tif', 0), \n             (f'{TRAIN_DIR}f38a6374c348f90b587e046aac6079959adf3835.tif', 1),\n            (f'{TRAIN_DIR}f38a6374c348f90b587e046aac6079959adf3835.tif', 0)])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Modelling","metadata":{"id":"2P4d0E5JbxbR"}},{"cell_type":"markdown","source":"### Dataset","metadata":{"id":"yZ9XuasjNejQ"}},{"cell_type":"code","source":"BATCH_SIZE = 32\nimg_height = 96\nimg_width = 96\nMAX_EPOCHS = 2","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import flax\n@flax.struct.dataclass\nclass F1_score(metrics.Metric):\n    true_pos: jnp.array\n    pred_pos: jnp.array\n    actual_pos: jnp.array\n\n    @classmethod\n    def empty(cls):\n        return cls(true_pos=jnp.array(0, jnp.int32), pred_pos=jnp.array(0, jnp.int32), actual_pos=jnp.array(0, jnp.int32))\n    \n    @classmethod\n    def from_model_output(cls, *, logits: jnp.array, labels: jnp.array, **_) -> metrics.Metric:\n        assert logits.shape[-1] == 2, \"Expected binary logits.\"\n        preds = logits.argmax(axis=-1)\n        return cls(\n            true_pos=((preds == 1) & (labels == 1)).sum(), # predicted and ground truth is 1- positive class\n            pred_pos=(preds == 1).sum(), # sum of predicted positives\n            actual_pos=(labels == 1).sum() # sum of ground truth positive\n        )\n        \n    def merge(self, other: metrics.Metric) -> metrics.Metric:\n        return type(self)(\n            true_pos=self.true_pos + other.true_pos,\n            pred_pos=self.pred_pos + other.pred_pos,\n            actual_pos=self.actual_pos + other.actual_pos\n        )\n    def compute(self): # f1_score = 2 / (1/precision + 1/recall)\n        recall  = self.true_pos / self.actual_pos\n        precision = self.true_pos / self.pred_pos\n        return 2 / (1/recall + 1/precision)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''\nMathews Correlation Coefficient (MCC)\nmcc =  (tp * tn -  fp * fn)/sqrt( (pred_pos)(actual_pos)(actual_negative)(pred_negative))\n'''\n@flax.struct.dataclass\nclass MCC(metrics.Metric):\n    tp: jnp.array\n    tn: jnp.array\n    fp: jnp.array\n    fn: jnp.array\n    pred_pos: jnp.array\n    pred_neg: jnp.array\n    actual_pos: jnp.array\n    actual_neg: jnp.array\n    \n\n    @classmethod\n    def empty(cls):\n        return cls(tp=jnp.array(0, jnp.int32), tn=jnp.array(0, jnp.int32),\n                   fp=jnp.array(0, jnp.int32), fn=jnp.array(0, jnp.int32),\n                   pred_pos=jnp.array(0, jnp.int32), pred_neg=jnp.array(0, jnp.int32), \n                   actual_pos=jnp.array(0, jnp.int32), actual_neg=jnp.array(0, jnp.int32))\n    \n    @classmethod\n    def from_model_output(cls, *, logits: jnp.array, labels: jnp.array, **_) -> metrics.Metric:\n        assert logits.shape[-1] == 2, \"Expected binary logits.\"\n        preds = logits.argmax(axis=-1)\n        return cls(\n            tp=((preds == 1) & (labels == 1)).sum(), # predicted and ground truth is 1- positive class\n            tn=((preds == 0) & (labels == 0)).sum(), # predicted and ground truth is 1- positive class\n            fp=((preds == 1) & (labels == 0)).sum(), # predicted and ground truth is 1- positive class\n            fn=((preds == 0) & (labels == 1)).sum(), # predicted and ground truth is 1- positive class\n            pred_pos=(preds == 1).sum(), # sum of predicted positives\n            pred_neg=(preds == 0).sum(), # sum of predicted positives\n            actual_pos=(labels == 1).sum(), # sum of ground truth positive\n            actual_neg=(labels == 0).sum() # sum of ground truth positive\n        )\n        \n    def merge(self, other: metrics.Metric) -> metrics.Metric:\n        return type(self)(\n            tp=self.tp + other.tp,\n            tn=self.tn + other.tn,\n            fp=self.fp + other.fp,\n            fn=self.fn + other.fn,\n            pred_pos=self.pred_pos + other.pred_pos,\n            pred_neg=self.pred_neg + other.pred_neg,\n            actual_pos=self.actual_pos + other.actual_pos,\n            actual_neg=self.actual_neg + other.actual_neg,\n        )\n    def compute(self): # f1_score = 2 / (1/precision + 1/recall)\n        mcc = ( self.tp * self.tn - self.fp * self.fn )  / jnp.sqrt(self.pred_pos * self.actual_pos * self.actual_neg * self.pred_neg)\n        return mcc","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Flax dataclasses ## to compute metrics in eval model\n@struct.dataclass\nclass Metrics(metrics.Collection):\n    loss: metrics.Average.from_output('loss')\n    f1_score: F1_score\n    mcc: MCC","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class TrainState(train_state.TrainState):\n  metrics: Metrics","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# class Writer:\n#     cache: Dict[int, List[Tuple[Any, str]]\n#     def __init__(self, save_dir):\n#         self.save_dir = save_dir\n#     def add_scalar(tag: str, val: Any, key: int):\n#         cache[key] = (val, tag)\n        ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# trainer class\nclass Trainer:\n    def __init__(self, model, params, logger, key):\n        self.model = model\n        self.hparams = params\n        self.key = key\n        self.logger = logger # event logger\n        self.writer = SummaryWriter(f\"{self.hparams.log_dir}/{params.run_name}\") #log to tensorboard\n        self.hparams.chkpt_dir = f\"{self.hparams.chkpt_dir}/{params.run_name}\"\n        self._init_train_state()\n        self._configure_checkpointer()\n    \n\n    def _configure_checkpointer(self):\n        options = ocp.CheckpointManagerOptions(max_to_keep=self.hparams.max_epochs, save_interval_steps=1, enable_async_checkpointing=True, create=True)\n        path = epath.Path(os.path.abspath(self.hparams.chkpt_dir))\n        self.checkpoint_mngr = ocp.CheckpointManager(path, options=options, item_names =('state', 'hparams'))\n        self.logger.info(\"Checkpointer configured\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%add_to Trainer\ndef _init_train_state(self):\n    self.n_devices = jax.local_device_count(backend='tpu')\n    self.logger.info(f\"Number of devices found: {self.n_devices}\")\n    mesh = jax.make_mesh((self.n_devices,), ('batch',))\n    model_sharding = NamedSharding(mesh, P())\n    self.key, model_key = jr.split(self.key)\n    variables = self.model.init(model_key, jnp.ones((1,) + self.hparams.shape))\n    self._configure_optimizers(variables)\n    model_state = TrainState.create(\n        apply_fn=self.model.apply, params=variables[\"params\"], \n        tx=self.optim, metrics=Metrics.empty()\n    )\n    self.model_state = jax.device_put(model_state, model_sharding)\n    self.logger.info(\"Train state initialized\")\n    ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%add_to Trainer\ndef _configure_optimizers(self, variables):\n    scheduler = optax.exponential_decay(\n                    init_value=self.hparams.lr,\n                    transition_steps=1000,\n                    decay_rate=0.97\n                )\n    self.optim = optax.chain(\n        optax.clip_by_global_norm(1.0),  # Clip by the gradient by the global norm.\n        optax.scale_by_adam(),  # Use the updates from adam.\n        optax.scale_by_schedule(scheduler),  # Use the learning rate from the scheduler.\n        # Scale updates by -1 since optax.apply_updates is additive and we want to descend on the loss.\n        optax.scale(-1.0)\n    )\n    self.opt_state = self.optim.init(variables)\n    self.logger.info(\"Optimizers configured\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%add_to Trainer\n@staticmethod\n@jax.jit\ndef _step(model_state, batch):\n    # Executes a training loop.\n    x, y =  batch\n    y = y.reshape(-1)\n    x = x.reshape(-1, x.shape[-3], x.shape[-2], x.shape[-1])\n    def loss_fn(params):\n        logits = model_state.apply_fn({\"params\": params}, x)\n        loss = optax.softmax_cross_entropy_with_integer_labels(\n            logits=logits, labels=y).mean()\n        return loss\n    grads = jax.grad(loss_fn)(model_state.params)\n    model_state = model_state.apply_gradients(grads=grads)\n    return model_state","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%add_to Trainer\ndef fit(self, train_loader: Any, val_loader: Any):\n    best_model = (float('inf'), 0)\n    \n    mesh = jax.make_mesh((self.n_devices,), ('batch',))\n    data_sharding = NamedSharding(mesh, P('batch'))\n    \n    num_steps_per_epoch = train_loader.cardinality().numpy() // MAX_EPOCHS\n    \n    epoch_pbar = tqdm(range(1, MAX_EPOCHS+1), leave=True, total = MAX_EPOCHS)\n    for epoch in epoch_pbar:\n        epoch_pbar.set_description(f\"Epoch: {epoch}\")\n        for step, batch in enumerate(train_loader.as_numpy_iterator()):\n            batch = jax.device_put(batch, data_sharding)\n            self.model_state = Trainer._step(self.model_state, batch)\n            self.model_state, _ = Trainer._compute_metrics(self.model_state, batch)\n        metrics = self.model_state.metrics.compute()\n        tloss = jax.device_get(metrics['loss'])\n        # precision = jax.device_get(metrics['precision'])\n        # recall = jax.device_get(metrics['recall'])\n        # mcc = jax.device_get(metrics['mcc'])\n        # f1_score = 2 / (1/precision + 1/recall)\n        # f1_score = 2 / (1/precision + 1/recall)\n        self.writer.add_scalar(f\"train_loss/epoch_{epoch}\", np.asarray(tloss), epoch)\n        self.writer.add_scalar(f\"train_f1_score/epoch_{epoch}\", np.asarray(jax.device_get(metrics['f1_score'])), epoch)\n        self.writer.add_scalar(f\"train_mcc/epoch_{epoch}\", np.asarray(jax.device_get(metrics['mcc'])), epoch)\n        self.model_state = self.model_state.replace(metrics=self.model_state.metrics.empty())\n        # evaluation loop\n        test_state = self.model_state #copy of model state for eval\n        for batch in val_loader.as_numpy_iterator():\n            batch = jax.device_put(batch, data_sharding)\n            test_state, preds =  Trainer._compute_metrics(test_state, batch)\n            self.writer.add_pr_curve('pr_curve', np.asarray(batch[1].reshape(-1)), np.asarray(preds), epoch)\n        metrics = test_state.metrics.compute()\n        vloss = jax.device_get(metrics['loss'])\n        epoch_pbar.set_postfix(train_loss=tloss, val_loss=vloss)\n        self.writer.add_scalar(f\"val_loss/epoch_{epoch}/\", np.asarray(vloss), epoch)\n        self.writer.add_scalar(f\"val_f1_score/epoch_{epoch}\", np.asarray(jax.device_get(metrics['f1_score'])), epoch)\n        self.writer.add_scalar(f\"val_mcc/epoch_{epoch}/\", np.asarray(jax.device_get(metrics['mcc'])), epoch)\n        self.checkpoint_mngr.save(\n            epoch,\n            args=ocp.args.Composite(\n                state = ocp.args.StandardSave(test_state), # use the copy of the model with the eval stats\n                hparams = ocp.args.JsonSave(json.dumps(self.hparams))\n                ) \n            )\n        # track best model for checkpointing\n        best_model = min(best_model, (vloss, epoch))\n            # logger.add_hparams(self.hparams, metric_dict, run_name=self.hparams.run_name)\n    try:\n        self.checkpoint_mngr.wait_until_finished()\n        if self.hparams.save_best:\n            self.checkpoint_mngr.should_save(best_model[1]) #save only the best model\n            self.logger.info(f\"best model saved at epoch {best_model[1]} with loss {best_model[0]}\")\n    except Exception as e:\n        self.logger.error(f\"Error saving checkpoint: {e}\")\n        ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%add_to Trainer\n@staticmethod\n@jax.jit\ndef _compute_metrics(model_state, batch):\n    x, y =  batch\n    x = x.reshape(-1, x.shape[-3], x.shape[-2], x.shape[-1])\n    y = y.reshape(-1)\n    logits = model_state.apply_fn({\"params\": model_state.params}, x)\n    preds = jnp.argmax(logits, axis=-1)\n    loss = optax.softmax_cross_entropy_with_integer_labels( logits=logits, labels=y).mean()\n    metric_updates = model_state.metrics.single_from_model_output(\n        logits=logits, labels=y, loss=loss)\n    metrics = model_state.metrics.merge(metric_updates)\n    model_state = model_state.replace(metrics=metrics)\n    return model_state, preds","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%add_to Trainer\ndef predict(self, x):\n    return self.model_state.apply_fn({\"params\": self.model_state.params}, x)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%add_to Trainer    \n'''\n@brief: load trained model and saved params from checkpoint and return an instance of the Trainer class\n'''\n@staticmethod\ndef load_from_checkpoint(path, load_epoch: int = 0):\n    pass","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_class_weights(ds):\n    def count(counts, batch):\n        x, y = batch\n        class_1 = tf.cast(y == 1, tf.int32)\n        class_0 = tf.cast(y == 0, tf.int32)\n        counts['y_0'] += tf.reduce_sum(class_0)\n        counts['y_1'] += tf.reduce_sum(class_1)\n        return counts\n    counts = ds.reduce(\n        initial_state={'y_0': 0, 'y_1': 0},\n        reduce_func = count\n    )\n    counts = np.array([counts['y_0'].numpy(),\n                   counts['y_1'].numpy()]).astype(np.float32)\n    weights = counts/counts.sum()\n    return weights","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_dataset(dfs: Dict[str, Any], num_epochs: int=10, batch_size:int=32, split_ratio: float = 0.2,):\n    AUTOTUNE = tf.data.AUTOTUNE\n    train_datagen = ImageDataGenerator(rescale=1/255, validation_split=split_ratio, rotation_range=20, \n                                       width_shift_range=0.2, height_shift_range=0.2, \n                                       horizontal_flip=True, vertical_flip=True, \n                                       zoom_range=0.2, shear_range=0.2, fill_mode='nearest'\n                                      ) # data augmentation\n    train_generator = train_datagen.flow_from_dataframe(dataframe=dfs['train'][0], directory=dfs['train'][1], \n                                                        x_col='image_path', y_col='label', batch_size=1,\n                                                        target_size=(img_width, img_height), \n                                                        subset='training', class_mode='binary')\n    val_generator = train_datagen.flow_from_dataframe(dataframe=dfs['train'][0], directory=dfs['train'][1], \n                                             x_col='image_path',y_col='label', batch_size=1,\n                                            target_size=(img_width, img_height), subset='validation', class_mode='binary')\n    test_datagen = ImageDataGenerator(rescale=1/255)\n    test_generator = test_datagen.flow_from_dataframe(dataframe=dfs['test'][0], directory=dfs['test'][1], \n                                             x_col='path',y_col=None, batch_size=1,\n                                            target_size=(img_width, img_height), class_mode=None, shuffle=None)\n    train_ds = tf.data.Dataset.from_generator(\n        lambda: train_generator,\n        output_types=(tf.float32, tf.int32),\n        output_shapes=([None,img_width,img_height,3], [None])\n    ).cache()\n    val_ds = tf.data.Dataset.from_generator(\n        lambda: val_generator,\n        output_types=(tf.float32, tf.int32),\n        output_shapes=([None,img_width,img_height,3], [None])\n    ).cache()\n    test_ds = tf.data.Dataset.from_generator(\n        lambda: test_generator,\n        output_types=(tf.float32),\n        output_shapes=([None,img_width,img_height,3])\n    ).cache()\n    # class_weights = get_class_weights(train_ds)\n    train_ds = train_ds.shuffle(1024).batch(batch_size, drop_remainder=True).prefetch(buffer_size=AUTOTUNE)\n    # train_ds = train_ds.map(lambda extra_label, features_and_label: features_and_label) # drop extra_label returned from rejection_resample method\n    val_ds = val_ds.shuffle(1024).batch(batch_size, drop_remainder=True).prefetch(buffer_size=AUTOTUNE)\n    test_ds = test_ds.batch(batch_size, drop_remainder=True).prefetch(buffer_size=AUTOTUNE)\n    return train_ds.take(batch_size*2), val_ds.take(batch_size * 2), test_ds.take(batch_size * 2)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CNN(nn.Module):\n    \"\"\"A simple CNN model.\"\"\"\n    img_size: int = 32\n    out_dim: int = 1\n    \n    @nn.compact\n    def __call__(self, x):\n        x = nn.Conv(features=self.img_size, kernel_size=(3, 3))(x)\n        x = nn.relu(x)\n        x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n        x = nn.Conv(features=64, kernel_size=(3, 3))(x)\n        x = nn.relu(x)\n        x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n        x = x.reshape((x.shape[0], -1))  # flatten\n        x = nn.Dense(features=256)(x)\n        x = nn.relu(x)\n        x = nn.Dense(features=self.out_dim)(x)\n        return x\n\n\ndef create_model(img_size, out_dim):\n    return CNN(img_size=img_size, out_dim=out_dim)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from munch import DefaultMunch\n\nhparams = DefaultMunch.fromDict({\n    'batch_size': BATCH_SIZE,\n    'image_size': img_width,\n    'shape' : (img_width,) * 2 + (3,),\n    'run_name' : datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n    'out_dim' : 2,\n    'lr': 0.005,\n    'max_epochs': MAX_EPOCHS,\n    'log_dir': '/kaggle/working/',\n    'chkpt_dir': '/kaggle/working/'\n})","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import logging\n\nlogger = logging.getLogger(__name__)\nlogging.basicConfig(filename='cancer.log', level=logging.INFO)\nmodel = create_model(img_height, hparams.out_dim)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(model.tabulate(jax.random.key(0), jnp.ones((1, img_width, img_height, 3)),\n                   compute_flops=True, compute_vjp_flops=True))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dfs = {'train': (df_train, TRAIN_DIR), 'test': (df_test, TEST_DIR)}\ntrain_ds, val_ds, test_ds = get_dataset(dfs, num_epochs = MAX_EPOCHS, batch_size=BATCH_SIZE)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"key = jax.random.key(0)\ntrainer = Trainer(model, hparams, logger, key)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"hparams.log_dir+hparams.run_name","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%load_ext aim","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# self.hparams.log_dir}/{dt}\n%aim convert tensorboard --logdir /kaggle/working/20250604-181356","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%aim up","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.fit(train_ds, val_ds)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# class_weights = get_class_weights(train_ds.batch(BATCH_SIZE))\n# train_ds = train_ds.unbatch().rejection_resample(lambda x, y: y, \n#                                                     target_dist=[0.5, 0.5], \n#                                                     initial_dist=class_weights\n#                                                   ).shuffle(1024).batch(batch_size, drop_remainder=True)\n#     # train_ds = train_ds.map(lambda extra_label, features_and_label: features_and_label) # drop extra_label returned from rejection_resample method","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Hyperparameter Optimization Using Optuna","metadata":{"id":"o0JQhmdg2KIc"}},{"cell_type":"code","source":"NUM_TRIALS = 100","metadata":{"id":"PhehDQmS-SDm","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def objective(trial):\n    return 0","metadata":{"id":"T_DMGQcs0RYY","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\nstudy_name = \"cancer_project\"  # Unique identifier of the study.\nstorage = optuna.storages.InMemoryStorage()\nstorage_name = f\"sqlite:///{study_name}.db\"\nstudy = optuna.create_study(study_name=study_name, storage=storage_name, directions=[\"minimize\"], load_if_exists=True)\nstudy.set_metric_names([\"f1_score\"])\n\nstudy.optimize(objective, n_trials=NUM_TRIALS, timeout=600)","metadata":{"id":"YFPIjz6zL6oZ","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Number of trials on the Pareto front: {len(study.best_trials)}\")\n\nt1 = max(study.best_trials, key=lambda t: t.values[0])\nprint(\"Trial with highest accuracy: \")\nprint(f\"\\tnumber: {t1.number}\")\nprint(f\"\\tparams: {t1.params}\")\nprint(f\"\\tvalues: {t1.values}\")\nt2 = max(study.best_trials, key=lambda t: t.values[1])\nprint(\"Trial with best generalization capability (val_accuracy-train_accuracy): \")\nprint(f\"\\tnumber: {t2.number}\")\nprint(f\"\\tparams: {t2.params}\")\nprint(f\"\\tvalues: {t2.values}\")","metadata":{"id":"zPWLQyxhVkjm","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3df93eab-08a9-473c-afbd-ee2f30700bbd","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# run this cell to view the optuna dashboard in another window (following the link in the output cell)\n# https://stackoverflow.com/questions/76033104/launching-optuna-dashboard-in-google-colaboratory\nport =  9005\nstorage = optuna.storages.RDBStorage(f\"sqlite:////content/{study_name}.db\")\napp = wsgi(storage)\nhttpd = make_server(\"localhost\", port, app)\nthread = threading.Thread(target=httpd.serve_forever)\nthread.start()\ntime.sleep(3) # Wait until the server startup\n\nfrom google.colab import output\noutput.serve_kernel_port_as_window(port, path='/dashboard/') # follow the link in the output cell below to view the dashboard","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69},"id":"M8DSHNpudKEK","outputId":"d03c62b5-1774-4974-e499-3920eb8df158","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Alternatively, run the cells below to see the output of the hyperparameter tuning**","metadata":{"id":"-hijXF6AkVXy"}},{"cell_type":"code","source":"optuna.visualization.plot_pareto_front(study, target_names=[\"val_accuracy_score\", \"train_score-val_score\"])","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"id":"Mv_XUcqpprZa","outputId":"02b26218-c50b-4204-c28e-12723b366471","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"optuna.visualization.plot_param_importances(\n    study, target=lambda t: t.values[0], target_name=\"val_accuracy_score\"\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"id":"Mc3WoSRQqc8I","outputId":"2be221b0-d5c2-490a-b427-386b9d250979","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"optuna.visualization.plot_param_importances(\n    study, target=lambda t: t.values[1], target_name=\"train_score-val_score\"\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"id":"Q6rJGb4pwfS0","outputId":"05681cb1-1bba-415f-8911-1692f1d4bdf2","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"optuna.visualization.plot_contour(study, target=lambda t: t.values[0], target_name=\"val_accuracy_score\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":559},"id":"5CstLzXpelQZ","outputId":"8cfa266d-e601-4d54-9ece-993e3a317c36","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"optuna.visualization.plot_contour(study, target=lambda t: t.values[1], target_name=\"train_score-val_score\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"id":"NE23hdfsxQQe","outputId":"7a648bb1-595f-4a7f-9189-2f8eb7e0ef03","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_parallel_coordinate(study, target=lambda t: t.values[0], target_name=\"val_accuracy_score\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"id":"qYT0cFOZfKVN","outputId":"7b506df7-e5ef-4af3-ad24-42ae03b74ec5","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_parallel_coordinate(study, target=lambda t: t.values[1], target_name=\"train_score-val_score\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"id":"Ic_wrOQrxZmf","outputId":"fa2ed39e-5f90-49b3-e6fe-18ffbc1f76ee","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Disussion and Conclusion\n\n","metadata":{"id":"TuMhZDBd-bRp"}},{"cell_type":"markdown","source":"## References\n1. ","metadata":{"id":"m4yFLMM6HuQE"}},{"cell_type":"code","source":"","metadata":{"id":"ucb9t2nu_Xz2","trusted":true},"outputs":[],"execution_count":null}]}